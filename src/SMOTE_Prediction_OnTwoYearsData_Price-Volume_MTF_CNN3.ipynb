{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from datetime import timedelta \n",
    "import dateparser as dp\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyts.image import GramianAngularField\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from pyts.image import MarkovTransitionField\n",
    "from pyts.image import RecurrencePlot\n",
    "import io\n",
    "import time\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from statistics import mean\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = <s3_bucket_name>\n",
    "DATA_POINTS_PER_WINDOW = 21\n",
    "s3Res = boto3.resource('s3')\n",
    "bucket = s3Res.Bucket(BUCKET_NAME)\n",
    "labelledDataCommonPath = <path_to_download_dir_on_s3>\n",
    "tempDiskSaveLoc= <location_on_disk.png>\n",
    "s3Client = boto3.client('s3')\n",
    "INPUT_MATRIX_WIDTH = 21\n",
    "ENCODED_FEATURES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMTFMatrix(df, feature, index, bins=10, span=10):\n",
    "    X = [df.loc[(index - timedelta(minutes=span)) : (index + timedelta(minutes=span)), feature]]\n",
    "    if len(X[0]) != DATA_POINTS_PER_WINDOW:\n",
    "        print(\"MTF error..{} Length != {}, {} point={}\".format(feature, DATA_POINTS_PER_WINDOW, len(X[0]), index))\n",
    "        raise Exception('MTF Length != %d, %d' %(DATA_POINTS_PER_WINDOW, len(X[0]))) \n",
    "    \n",
    "    mtf = MarkovTransitionField(n_bins=bins, strategy='uniform', overlapping=False)\n",
    "    x_mtf = mtf.fit_transform(X)\n",
    "    return x_mtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = s3Res.Bucket(BUCKET_NAME)\n",
    "\n",
    "csvFileList = []\n",
    "\n",
    "for my_bucket_object in my_bucket.objects.filter(Prefix=labelledDataCommonPath):\n",
    "    if '.csv' in my_bucket_object.key:\n",
    "        print(my_bucket_object.key)\n",
    "        csvFileList.append(my_bucket_object.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSaveLocOnDisk = <location_to_h5_model_file>\n",
    "\n",
    "mtfCnn3 = load_model(modelSaveLocOnDisk)\n",
    "mtfCnn3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fileIndex = 0\n",
    "\n",
    "encodedFeatures = ['Price', 'Volume']\n",
    "encoded_feature_count = len(encodedFeatures)\n",
    "minVicinity = 20\n",
    "\n",
    "NUMBER_OF_FILES_USEDTO_TRAIN = 20\n",
    "\n",
    "predictionDf = pd.DataFrame(columns = ['CoinName', 'PredictedLabel', 'Label'])\n",
    "\n",
    "for file_name in csvFileList[NUMBER_OF_FILES_USEDTO_TRAIN:23]:\n",
    "    print(file_name)\n",
    "    \n",
    "    coin_name = file_name.split('/')[-1].split('_')[1]\n",
    "    fileIndex +=1\n",
    "    obj = s3Client.get_object(Bucket = BUCKET_NAME, Key = file_name)\n",
    "    df = pd.read_csv(obj['Body'], index_col='0', parse_dates=True)\n",
    "    mismatches = []\n",
    "    \n",
    "    df['CoinName'] = coin_name\n",
    "    df['PredictedLabel'] = 0\n",
    "    \n",
    "    for i in tqdm(df.index):\n",
    "        mat = np.zeros((1, DATA_POINTS_PER_WINDOW, DATA_POINTS_PER_WINDOW, encoded_feature_count), 'float32')    \n",
    "        try:\n",
    "            price = getMTFMatrix(df, 'Price', i)\n",
    "            vol = getMTFMatrix(df, 'Volume', i)\n",
    "        except:\n",
    "            print(\"An exception occurred for coin when GADF encoded {} at {}\".format(coin_name, i.strftime('%Y-%m-%d %H%M%S') ))\n",
    "            continue\n",
    "        \n",
    "        mat[0][:,:,0] = price[0]\n",
    "        mat[0][:,:,1] = vol[0]\n",
    "        \n",
    "        y_pred_R = np.round(mtfCnn3.predict(mat))\n",
    "        df.loc[i, 'PredictedLabel'] = y_pred_R[0][0]\n",
    "        \n",
    "        if (df.loc[i, 'Label'] != y_pred_R[0][0]):\n",
    "            mismatches.append( (i.strftime('%Y-%m-%d %H%M%S'), df.loc[i, 'Label'], y_pred_R[0][0]) )\n",
    "            \n",
    "    if  (len(mismatches) > 50 ):\n",
    "        print ('******** Number of mismatches for coin{} is high={} !!!'.format(coin_name, len(mismatches)))\n",
    "        print(mismatches)\n",
    "    \n",
    "    predictionDf = pd.concat([predictionDf, df[['CoinName', 'PredictedLabel', 'Label']]], axis=0)\n",
    "    \n",
    "    print('-------------- processed files %d' %fileIndex)\n",
    "    print(psutil.virtual_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictionDf['PredictedLabel'].values\n",
    "act = predictionDf['Label'].values\n",
    "\n",
    "predictionDf.to_csv(<predictions_csv>, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(predictionDf.Label, predictionDf.PredictedLabel)\n",
    "print(conf)\n",
    "\n",
    "clfr = classification_report(predictionDf.Label, predictionDf.PredictedLabel, output_dict=True)\n",
    "print(clfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "finConf=np.zeros((2,2), dtype=int)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "         finConf[i][j] += conf[i][j]\n",
    "                \n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(finConf/np.sum(finConf), annot=True, fmt='.2%', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
