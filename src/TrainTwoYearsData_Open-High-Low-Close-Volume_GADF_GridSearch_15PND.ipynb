{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from datetime import timedelta \n",
    "\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import psutil\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "import random\n",
    "from keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from statistics import mean\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelledDataCommonPath = <path_to_labelleddata_dir_on_s3>\n",
    "featureCombinationName = 'Open_High_Low_Close_Volume_GADF_15PPND_New'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = <s3_bucket_name>\n",
    "s3Res = boto3.resource('s3')\n",
    "s3Client = boto3.client('s3')\n",
    "my_bucket = s3Res.Bucket(BUCKET_NAME)\n",
    "\n",
    "INPUT_MATRIX_WIDTH = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=\"{}/{}/\".format(labelledDataCommonPath, featureCombinationName)\n",
    "\n",
    "X_data=[]\n",
    "Y_data=[]\n",
    "\n",
    "for my_bucket_object in my_bucket.objects.filter(Prefix=prefix):\n",
    "    if 'x.pkl' in my_bucket_object.key:\n",
    "        print(my_bucket_object.key)\n",
    "        response_X = s3Client.get_object(Bucket=BUCKET_NAME, Key=my_bucket_object.key)\n",
    "        x_body=response_X['Body'].read()\n",
    "        X_data.append(pickle.loads(x_body))\n",
    "    elif 'y.pkl' in my_bucket_object.key:\n",
    "        print(my_bucket_object.key)\n",
    "        response_Y = s3Client.get_object(Bucket=BUCKET_NAME, Key=my_bucket_object.key)\n",
    "        y_body=response_Y['Body'].read()\n",
    "        Y_data.append(pickle.loads(y_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dataBinary = np.array(Y_data)\n",
    "Y_dataBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dataArr = np.array(Y_data)\n",
    "X_dataArr = np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation='relu', dropout=True, pooling=True):\n",
    "    cnn=Sequential()\n",
    "    cnn.add(Conv2D(filters=32, kernel_size=(2,2), padding='same', activation=activation, input_shape=(INPUT_MATRIX_WIDTH, INPUT_MATRIX_WIDTH, 5)))\n",
    "    \n",
    "    if pooling==True:\n",
    "        cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    cnn.add(Conv2D(filters=32, kernel_size=(2,2), padding='same', activation=activation))\n",
    "    \n",
    "    if pooling==True:\n",
    "        cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    if dropout==True:\n",
    "        cnn.add(Dropout(0.25))\n",
    "    \n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(128, activation=activation))\n",
    "    \n",
    "    if dropout==True:\n",
    "        cnn.add(Dropout(0.5))\n",
    "    \n",
    "    cnn.add(Dense(1, activation='sigmoid'))\n",
    "    cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=25, verbose=0)\n",
    "\n",
    "activation=['relu', 'tanh']\n",
    "dropout=[True, False]\n",
    "pooling=[True, False]\n",
    "batch_size=[50, 100]\n",
    "\n",
    "param_grid=dict(activation=activation, dropout=dropout, pooling=pooling, batch_size=batch_size)\n",
    "\n",
    "grid=GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_dataArr, Y_dataBinary)\n",
    "\n",
    "print(\"best %f using %s\" %(grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32, 32, 128, pooling=false, dropout=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = create_model(activation='relu', dropout=False, pooling=True)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=3)\n",
    "history = []\n",
    "confusions= []\n",
    "classifReports= []\n",
    "\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(X_dataArr, Y_dataBinary):\n",
    "    print('Running fold [%d]'.ljust(100,'*') %fold)\n",
    "    fold +=1\n",
    "    \n",
    "    cnn = create_model(activation='relu', dropout=False, pooling=True)\n",
    "    \n",
    "    x_train, x_test = X_dataArr[train], X_dataArr[test]\n",
    "    y_train, y_test = Y_dataBinary[train], Y_dataBinary[test]\n",
    "    \n",
    "    hist = cnn.fit(x=x_train, y=y_train, validation_split=0.2, epochs=40, batch_size=100, verbose=0)\n",
    "    history.append(hist)\n",
    "    \n",
    "    y_pred = cnn.predict(x_test)\n",
    "\n",
    "    y_pred_R = np.round(y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred_R)\n",
    "    confusions.append(conf)\n",
    "    \n",
    "    clfr = classification_report(y_test, y_pred_R, output_dict=True)\n",
    "    print(clfr)\n",
    "    classifReports.append(clfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=2\n",
    "plt.plot(history[j].history['acc'])\n",
    "plt.plot(history[j].history['val_acc'])\n",
    "plt.legend(['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[j].history['loss'])\n",
    "plt.plot(history[j].history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re running for epoch 22\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "history = []\n",
    "confusions= []\n",
    "classifReports= []\n",
    "\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(X_dataArr, Y_dataBinary):\n",
    "    print('Running fold [%d]'.ljust(100,'*') %fold)\n",
    "    fold +=1\n",
    "    \n",
    "    cnn = create_model(activation='relu', dropout=False, pooling=True)\n",
    "    \n",
    "    x_train, x_test = X_dataArr[train], X_dataArr[test]\n",
    "    y_train, y_test = Y_dataBinary[train], Y_dataBinary[test]\n",
    "    \n",
    "    hist = cnn.fit(x=x_train, y=y_train, validation_split=0.2, epochs=22, batch_size=100, verbose=0)\n",
    "    history.append(hist)\n",
    "    \n",
    "    y_pred = cnn.predict(x_test)\n",
    "\n",
    "    y_pred_R = np.round(y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred_R)\n",
    "    confusions.append(conf)\n",
    "    \n",
    "    clfr = classification_report(y_test, y_pred_R, output_dict=True)\n",
    "    print(clfr)\n",
    "    classifReports.append(clfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=[ rep['1']['f1-score'] for rep in classifReports ]\n",
    "recal=[ rep['1']['recall'] for rep in classifReports ]\n",
    "prec=[ rep['1']['precision'] for rep in classifReports ]\n",
    "\n",
    "print(mean(f1))\n",
    "print(mean(recal))\n",
    "print(mean(prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finConf=np.zeros((2,2), dtype=int)\n",
    "for elem in confusions:\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "             finConf[i][j] += elem[i][j]\n",
    "                \n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(finConf/np.sum(finConf), annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macroPrec=[]\n",
    "macroRecall=[]\n",
    "macrof1=[]\n",
    "\n",
    "for elem in classifReports:\n",
    "    macroPrec.append(elem['macro avg']['precision'])\n",
    "    macroRecall.append(elem['macro avg']['recall'])\n",
    "    macrof1.append(elem['macro avg']['f1-score'])\n",
    "    \n",
    "print(np.mean(macroPrec))\n",
    "print(np.mean(macroRecall))\n",
    "print(np.mean(macrof1))\n",
    "\n",
    "\n",
    "weighPrec=[]\n",
    "weighRecall=[]\n",
    "weighf1=[]\n",
    "\n",
    "for elem in classifReports:\n",
    "    weighPrec.append(elem['weighted avg']['precision'])\n",
    "    weighRecall.append(elem['weighted avg']['recall'])\n",
    "    weighf1.append(elem['weighted avg']['f1-score'])\n",
    "    \n",
    "print(np.mean(weighPrec))\n",
    "print(np.mean(weighRecall))\n",
    "print(np.mean(weighf1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search 64,64,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_64(dropout=True, pooling=True, dropoutp1=0.25, dropoutp2=0.5):\n",
    "    cnn=Sequential()\n",
    "    cnn.add(Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu', input_shape=(INPUT_MATRIX_WIDTH, INPUT_MATRIX_WIDTH, 5)))\n",
    "    \n",
    "    if pooling==True:\n",
    "        cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    cnn.add(Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu'))\n",
    "    \n",
    "    if pooling==True:\n",
    "        cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    if dropout==True:\n",
    "        cnn.add(Dropout(dropoutp1))\n",
    "    \n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    if dropout==True:\n",
    "        cnn.add(Dropout(dropoutp2))\n",
    "    \n",
    "    cnn.add(Dense(1, activation='sigmoid'))\n",
    "    cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model_64, epochs=25, verbose=0)\n",
    "\n",
    "dropout=[True, False]\n",
    "pooling=[True, False]\n",
    "batch_size=[50, 100]\n",
    "dropoutp1 =[0.25,0.5]\n",
    "dropoutp2 =[0.25,0.5]\n",
    "\n",
    "param_grid=dict(dropout=dropout, pooling=pooling, batch_size=batch_size, dropoutp1=dropoutp1, dropoutp2=dropoutp2)\n",
    "\n",
    "grid=GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_dataArr, Y_dataBinary)\n",
    "\n",
    "print(\"best %f using %s\" %(grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=3)\n",
    "history = []\n",
    "confusions= []\n",
    "classifReports= []\n",
    "\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(X_dataArr, Y_dataBinary):\n",
    "    print('Running fold [%d]'.ljust(100,'*') %fold)\n",
    "    fold +=1\n",
    "    \n",
    "    cnn = create_model_64(dropout=True, pooling=True, dropoutp1=0.25, dropoutp2=0.5)\n",
    "    \n",
    "    x_train, x_test = X_dataArr[train], X_dataArr[test]\n",
    "    y_train, y_test = Y_dataBinary[train], Y_dataBinary[test]\n",
    "    \n",
    "    hist = cnn.fit(x=x_train, y=y_train, validation_split=0.2, epochs=40, batch_size=50, verbose=0)\n",
    "    history.append(hist)\n",
    "    \n",
    "    y_pred = cnn.predict(x_test)\n",
    "\n",
    "    y_pred_R = np.round(y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred_R)\n",
    "    confusions.append(conf)\n",
    "    \n",
    "    clfr = classification_report(y_test, y_pred_R, output_dict=True)\n",
    "    print(clfr)\n",
    "    classifReports.append(clfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = create_model_64(dropout=True, pooling=True, dropoutp1=0.25, dropoutp2=0.5)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=2\n",
    "plt.plot(history[j].history['acc'])\n",
    "plt.plot(history[j].history['val_acc'])\n",
    "\n",
    "plt.legend(['acc','val_acc'])\n",
    "\n",
    "f1=[ rep['1']['f1-score'] for rep in classifReports ]\n",
    "recal=[ rep['1']['recall'] for rep in classifReports ]\n",
    "prec=[ rep['1']['precision'] for rep in classifReports ]\n",
    "\n",
    "print(mean(f1))\n",
    "print(mean(recal))\n",
    "print(mean(prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[j].history['loss'])\n",
    "plt.plot(history[j].history['val_loss'])\n",
    "plt.legend(['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re run for epoch 14\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "history = []\n",
    "confusions= []\n",
    "classifReports= []\n",
    "\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(X_dataArr, Y_dataBinary):\n",
    "    print('Running fold [%d]'.ljust(100,'*') %fold)\n",
    "    fold +=1\n",
    "    \n",
    "    cnn = create_model_64(dropout=True, pooling=True, dropoutp1=0.25, dropoutp2=0.5)\n",
    "    \n",
    "    x_train, x_test = X_dataArr[train], X_dataArr[test]\n",
    "    y_train, y_test = Y_dataBinary[train], Y_dataBinary[test]\n",
    "    \n",
    "    hist = cnn.fit(x=x_train, y=y_train, validation_split=0.2, epochs=14, batch_size=50, verbose=0)\n",
    "    history.append(hist)\n",
    "    \n",
    "    y_pred = cnn.predict(x_test)\n",
    "\n",
    "    y_pred_R = np.round(y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred_R)\n",
    "    confusions.append(conf)\n",
    "    \n",
    "    clfr = classification_report(y_test, y_pred_R, output_dict=True)\n",
    "    print(clfr)\n",
    "    classifReports.append(clfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finConf=np.zeros((2,2), dtype=int)\n",
    "for elem in confusions:\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "             finConf[i][j] += elem[i][j]\n",
    "                \n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(finConf/np.sum(finConf), annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macroPrec=[]\n",
    "macroRecall=[]\n",
    "macrof1=[]\n",
    "\n",
    "for elem in classifReports:\n",
    "    macroPrec.append(elem['macro avg']['precision'])\n",
    "    macroRecall.append(elem['macro avg']['recall'])\n",
    "    macrof1.append(elem['macro avg']['f1-score'])\n",
    "    \n",
    "print(np.mean(macroPrec))\n",
    "print(np.mean(macroRecall))\n",
    "print(np.mean(macrof1))\n",
    "\n",
    "\n",
    "weighPrec=[]\n",
    "weighRecall=[]\n",
    "weighf1=[]\n",
    "\n",
    "for elem in classifReports:\n",
    "    weighPrec.append(elem['weighted avg']['precision'])\n",
    "    weighRecall.append(elem['weighted avg']['recall'])\n",
    "    weighf1.append(elem['weighted avg']['f1-score'])\n",
    "    \n",
    "print(np.mean(weighPrec))\n",
    "print(np.mean(weighRecall))\n",
    "print(np.mean(weighf1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 64, 64, 128, pooling=false, dropout=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=3)\n",
    "history = []\n",
    "confusions= []\n",
    "classifReports= []\n",
    "\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(X_dataArr, Y_dataBinary):\n",
    "    print('Running fold [%d]'.ljust(100,'*') %fold)\n",
    "    fold +=1\n",
    "    \n",
    "    cnn=Sequential()\n",
    "    cnn.add(Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu', input_shape=(INPUT_MATRIX_WIDTH, INPUT_MATRIX_WIDTH, 5)))\n",
    "    cnn.add(Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu'))\n",
    "    cnn.add(Dropout(0.25))\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(128, activation='relu'))\n",
    "    cnn.add(Dropout(0.5))\n",
    "    cnn.add(Dense(1, activation='sigmoid'))\n",
    "    cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    x_train, x_test = X_dataArr[train], X_dataArr[test]\n",
    "    y_train, y_test = Y_dataBinary[train], Y_dataBinary[test]\n",
    "    \n",
    "    hist = cnn.fit(x=x_train, y=y_train, validation_split=0.2, epochs=40, batch_size=50, verbose=0)\n",
    "    history.append(hist)\n",
    "    \n",
    "    y_pred = cnn.predict(x_test)\n",
    "\n",
    "    y_pred_R = np.round(y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred_R)\n",
    "    confusions.append(conf)\n",
    "    \n",
    "    clfr = classification_report(y_test, y_pred_R, output_dict=True)\n",
    "    print(clfr)\n",
    "    classifReports.append(clfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=2\n",
    "plt.plot(history[j].history['acc'])\n",
    "plt.plot(history[j].history['val_acc'])\n",
    "plt.plot(history[j].history['loss'])\n",
    "plt.plot(history[j].history['val_loss'])\n",
    "plt.legend(['acc','val_acc','loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=[ rep['1']['f1-score'] for rep in classifReports ]\n",
    "recal=[ rep['1']['recall'] for rep in classifReports ]\n",
    "prec=[ rep['1']['precision'] for rep in classifReports ]\n",
    "\n",
    "print(mean(f1))\n",
    "print(mean(recal))\n",
    "print(mean(prec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 64, 64, 256, pooling=false, dropout=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=3)\n",
    "history = []\n",
    "confusions= []\n",
    "classifReports= []\n",
    "\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(X_dataArr, Y_dataBinary):\n",
    "    print('Running fold [%d]'.ljust(100,'*') %fold)\n",
    "    fold +=1\n",
    "    \n",
    "    cnn=Sequential()\n",
    "    cnn.add(Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu', input_shape=(INPUT_MATRIX_WIDTH, INPUT_MATRIX_WIDTH, 5)))\n",
    "    cnn.add(Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu'))\n",
    "    cnn.add(Dropout(0.25))\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(256, activation='relu'))\n",
    "    cnn.add(Dropout(0.5))\n",
    "    cnn.add(Dense(1, activation='sigmoid'))\n",
    "    cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    x_train, x_test = X_dataArr[train], X_dataArr[test]\n",
    "    y_train, y_test = Y_dataBinary[train], Y_dataBinary[test]\n",
    "    \n",
    "    hist = cnn.fit(x=x_train, y=y_train, validation_split=0.2, epochs=20, batch_size=50, verbose=0)\n",
    "    history.append(hist)\n",
    "    \n",
    "    y_pred = cnn.predict(x_test)\n",
    "\n",
    "    y_pred_R = np.round(y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred_R)\n",
    "    confusions.append(conf)\n",
    "    \n",
    "    clfr = classification_report(y_test, y_pred_R, output_dict=True)\n",
    "    print(clfr)\n",
    "    classifReports.append(clfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=2\n",
    "plt.plot(history[j].history['acc'])\n",
    "plt.plot(history[j].history['val_acc'])\n",
    "plt.plot(history[j].history['loss'])\n",
    "plt.plot(history[j].history['val_loss'])\n",
    "plt.legend(['acc','val_acc','loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=[ rep['1']['f1-score'] for rep in classifReports ]\n",
    "recal=[ rep['1']['recall'] for rep in classifReports ]\n",
    "prec=[ rep['1']['precision'] for rep in classifReports ]\n",
    "\n",
    "print(mean(f1))\n",
    "print(mean(recal))\n",
    "print(mean(prec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
