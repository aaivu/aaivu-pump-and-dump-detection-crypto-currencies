{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from datetime import timedelta \n",
    "import dateparser as dp\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyts.image import GramianAngularField\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from pyts.image import MarkovTransitionField\n",
    "from pyts.image import RecurrencePlot\n",
    "import io\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gc\n",
    "import psutil\n",
    "import pickle\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "import random\n",
    "from keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from statistics import mean\n",
    "import seaborn as sns\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = <s3_bucket_name>\n",
    "DATA_POINTS_PER_WINDOW = 21\n",
    "s3Res = boto3.resource('s3')\n",
    "bucket = s3Res.Bucket(BUCKET_NAME)\n",
    "commonPath = <s3_path>\n",
    "labelledDataCommonPath = '{}/SMOTED_DATA'.format(commonPath)\n",
    "tempDiskSaveLoc= '15PNDImage.png'\n",
    "s3Client = boto3.client('s3')\n",
    "INPUT_MATRIX_WIDTH = 21\n",
    "ENCODED_FEATURES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGAFMatrix(df, feature, index, method='summation', span=10):\n",
    "    X = [df.loc[(index - timedelta(minutes=span)) : (index + timedelta(minutes=span)), feature]]\n",
    "    \n",
    "    if len(X[0]) != DATA_POINTS_PER_WINDOW:\n",
    "        raise Exception('GAF Length != %d, %d' %(DATA_POINTS_PER_WINDOW, len(X[0]))) \n",
    "    \n",
    "    gaf = GramianAngularField(method = method, overlapping = False)\n",
    "    x_gaf = gaf.fit_transform(X)\n",
    "    return x_gaf\n",
    "    \n",
    "\n",
    "def getMTFMatrix(df, feature, index, bins=10, span=10):\n",
    "    X = [df.loc[(index - timedelta(minutes=span)) : index, feature]]\n",
    "    if len(X[0]) != DATA_POINTS_PER_WINDOW:\n",
    "        raise Exception('MTF Length != %d, %d' %(DATA_POINTS_PER_WINDOW, len(X[0]))) \n",
    "    \n",
    "    mtf = MarkovTransitionField(n_bins=bins, strategy='uniform', overlapping=False)\n",
    "    x_mtf = mtf.fit_transform(X)\n",
    "    return x_mtf\n",
    "\n",
    "\n",
    "def getRecurrencePlotMatrix(df, feature, index, threshold=None, span=10):\n",
    "    X = [df.loc[(index - timedelta(minutes=span)) : index, feature]]\n",
    "    if len(X[0]) != DATA_POINTS_PER_WINDOW:\n",
    "        raise Exception('RP Length != %d, %d' %(DATA_POINTS_PER_WINDOW, len(X[0])))\n",
    "    \n",
    "    rp = RecurrencePlot(threshold = threshold)\n",
    "    x_rp = rp.fit_transform(X)\n",
    "    return x_rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = s3Res.Bucket(BUCKET_NAME)\n",
    "\n",
    "csvFileList = []\n",
    "\n",
    "for my_bucket_object in my_bucket.objects.filter(Prefix=labelledDataCommonPath):\n",
    "    if '.csv' in my_bucket_object.key:\n",
    "        print(my_bucket_object.key)\n",
    "        csvFileList.append(my_bucket_object.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSaveLocOnDisk = 'GADF_CNN5.h5'\n",
    "\n",
    "gadfCnn5 = load_model(modelSaveLocOnDisk)\n",
    "gadfCnn5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "fileIndex = 0\n",
    "encodedFeatures = ['Price', 'Volume']\n",
    "encoded_feature_count = len(encodedFeatures)\n",
    "minVicinity = 20\n",
    "\n",
    "NUMBER_OF_FILES_USEDTO_TRAIN = 20\n",
    "\n",
    "predictionDf = pd.DataFrame(columns = ['CoinName', 'PredictedLabel', 'Label'])\n",
    "\n",
    "for file_name in csvFileList[NUMBER_OF_FILES_USEDTO_TRAIN:24]:\n",
    "    print(file_name)\n",
    "    \n",
    "    coin_name = file_name.split('/')[-1].split('_')[1]\n",
    "    fileIndex +=1\n",
    "    obj = s3Client.get_object(Bucket = BUCKET_NAME, Key = file_name)\n",
    "    df = pd.read_csv(obj['Body'], index_col='0', parse_dates=True)\n",
    "    mismatches = []\n",
    "    \n",
    "    df['CoinName'] = coin_name\n",
    "    df['PredictedLabel'] = 0\n",
    "    \n",
    "    for i in tqdm(df.index):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        mat = np.zeros((1, DATA_POINTS_PER_WINDOW, DATA_POINTS_PER_WINDOW, encoded_feature_count), 'float32')    \n",
    "        try:\n",
    "            price = getGAFMatrix(df, 'Price', i, method='difference', span=10)\n",
    "            vol = getGAFMatrix(df, 'Volume', i, method='difference', span=10)\n",
    "        except:\n",
    "            print(\"An exception occurred for coin when GADF encoded {} at {}\".format(coin_name, i.strftime('%Y-%m-%d %H%M%S') ))\n",
    "            continue\n",
    "        \n",
    "        mat[0][:,:,0] = price[0]\n",
    "        mat[0][:,:,1] = vol[0]\n",
    "        \n",
    "        y_pred_R = np.round(gadfCnn5.predict(mat))\n",
    "        \n",
    "        end = time.time()\n",
    "        print(end - start)\n",
    "        print(\"$$$\")\n",
    "        \n",
    "\n",
    "        df.loc[i, 'PredictedLabel'] = y_pred_R[0][0]\n",
    "        \n",
    "        if (df.loc[i, 'Label'] != y_pred_R[0][0]):\n",
    "            mismatches.append( (i.strftime('%Y-%m-%d %H%M%S'), df.loc[i, 'Label'], y_pred_R[0][0]) )\n",
    "    \n",
    "    if  (len(mismatches) > 50 ):\n",
    "        print ('******** Number of mismatches for coin{} is high={} !!!'.format(coin_name, len(mismatches)))\n",
    "        print(mismatches)\n",
    "    \n",
    "    predictionDf = pd.concat([predictionDf, df[['CoinName', 'PredictedLabel', 'Label']]], axis=0)\n",
    "    \n",
    "    print('-------------- processed files %d' %fileIndex)\n",
    "    print(psutil.virtual_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictionDf['PredictedLabel'].values\n",
    "act = predictionDf['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionDf.to_csv('gadfcnn5_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(act, pred)\n",
    "print(conf)\n",
    "\n",
    "clfr = classification_report(act, pred, output_dict=True)\n",
    "print(clfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "finConf=np.zeros((2,2), dtype=int)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "         finConf[i][j] += conf[i][j]\n",
    "                \n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(finConf/np.sum(finConf), annot=True, fmt='.2%', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
